\chapter*{emulation}
\addcontentsline{toc}{chapter}{emulation}
\begin{center}
\vspace{2cm}
\begin{flushright}
\large
\textit{Human beings are creatures who practice and train, creatures who are free to reach beyond themselves in the process of becoming.}\\
\textbf{Peter Sloterdijk} \citep{sloterdijk2014}
\end{flushright}
\vspace{2cm}
% \vspace*{\fill}
\end{center}
\normalsize

I spent years understanding what this means to me. I learned about the mask I put on unknowingly \u2014 to fit in, to attract less attention, to avoid conflicts and misunderstandings. I learned the consequences of wearing this mask.

Living often feels like running a sophisticated emulation program on a computer. On the surface, the emulated environment mimics a typical operating system, seamlessly performing tasks and following expected protocols. However, behind this facade of normality, a complex system is working overtime to replicate behaviors and responses that come naturally to others. Constantly striving to appear organized, focused, and in control, while battling distraction, impulsivity, and a torrent of unfiltered thoughts.

Just as an emulated system can lag or crash when overloaded, I often become overwhelmed and fatigued by the continuous effort to conform to neurotypical standards. The emulation requires immense mental resources, leading to burnout and a sense of disconnection from my authentic self.

This section questions the boundaries between imitation and authenticity. Just as in an imperfectly emulated operating system, deeper layers can only be revealed by interaction. While imitation seeks to replicate a style or a pattern, emulation aims to recreate functionality based on different technical resources.

In his essay \textit{The Work of Art in the Age of Mechanical Reproduction}, Walter Benjamin describes the uniqueness of a piece as its \textit{aura}, and argues that mechanical reproduction diminishes the aura of an original work of art, affecting its authenticity \citep{benjamin1935}. The rise of digital art and AI technologies further complicates the discussion on authenticity. In the digital realm, the ease of replication and distribution encourages a reevaluation of authenticity. The available tools contradict the traditional criteria for what constitutes an original piece, and the notion of what adds value.

The writing of this book has been assisted by a state-of-the-art large language model (LLM) that seeks to emulate human responses. LLMs are powerful examples of emulation in action, imitating human-like language production while simultaneously challenging traditional notions of originality and authenticity.

Large language models are trained on gigantic datasets of text to emulate human language. They predict and generate text that mimics human communication, often indistinguishable from content created by people. LLMs emulate linguistic styles, cultural idioms, and intellectual processes by identifying patterns in existing data. This parallels how an emulator replicates the functionality of hardware or software.

LLMs as a tool gave rise to \textit{prompt engineering}. With clear directions, it is possible to establish a form of collaboration between humans and AI, potentially enhancing (and enhanced by) pre-existing research tools (internet, books, lectures, other people...). Through the creative writing of prompts as the conceptual foundation, the user curates the AI's emulation capabilities.

The interaction between user and model creates a feedback loop, where the human evaluates, adjusts, and improves the AI's outputs, validating them through external resources and utilizing preexisting knowledge to focus the attention of the generated text.

If authenticity lies in the human origin of a work, AI content lacks it. However, if authenticity is tied to the experience of the audience, LLMs can produce texts that feel authentic, even if not created by a human. AI operates by recombining existing data in patterns that make sense from a linguistic perspective rather than originating ideas independently. I would argue that human brains do the exact same thing. Most innovations, whether in art, science, or technology, are recombinations or extensions of existing ideas. The difference resides in the fact that when we, \u2014 biological algorithms \u2014 recombine ideas, we do so with intent and purpose, often driven by emotions, curiosity, or specific goals, as well as the ability to reflect on our thought processes. This intentionality adds layers of meaning that is (currently) not present in any piece of software.

While examining the interplay between imitation, authenticity, and emulation, we find parallels not only in art and technology but also in human behavior. One example is the phenomenon of \textit{masking} in neurodivergent individuals, where individuals consciously or unconsciously emulate neurotypical behavior to navigate social environments. This behavioral emulation aligns conceptually with the workings of LLMs and raises questions about authenticity in human interaction.

Masking involves the effortful emulation of socially expected behaviors, often by suppressing or adapting natural tendencies. This is common in individuals with autism, ADHD, or other neurodivergent conditions as they adapt to environments shaped by neurotypical norms. It can be understood as a form of emulation, the execution of a learned social script to fit into expected patterns.

Like LLMs, I often rely on a database of observed social behaviors, recombining them to produce contextually appropriate responses, often without a real understanding of a deeper meaning and without feeling an intrinsic connection to the behavior.

Am I authentic?

